{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39098609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── Standard­bibliothek ────────────────────────────────────────────────────────\n",
    "import math\n",
    "\n",
    "# ─── Data Handling ───────────────────────────────────────────────────────────────\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ─── Visualisierung ────────────────────────────────────────────────────────────\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ─── Scikit-Learn: Pipeline & Preprocessing ─────────────────────────────────────\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import (\n",
    "    OneHotEncoder,\n",
    "    OrdinalEncoder,\n",
    "    StandardScaler\n",
    ")\n",
    "\n",
    "# ─── Scikit-Learn: Modell­auswahl & Hyperparameter­suche ─────────────────────────\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    StratifiedKFold,\n",
    "    RandomizedSearchCV\n",
    ")\n",
    "\n",
    "# ─── Scikit-Learn: Modelle & Feature Selection ──────────────────────────────────\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# ─── Scikit-Learn: Metriken & Aus­gabe ──────────────────────────────────────────\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    roc_auc_score,\n",
    "    ConfusionMatrixDisplay,\n",
    "    RocCurveDisplay\n",
    ")\n",
    "\n",
    "# ─── Eigene Encoder / Transformer ────────────────────────────────────────────────\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "# from category_encoders import BinaryEncoder  # falls du die Bibliothek nutzt\n",
    "# oder definiere hier deinen eigenen BinaryEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ca0aa8",
   "metadata": {},
   "source": [
    "## 1. Daten laden und vorbereiten\n",
    "Zunächst laden wir den Mushroom-Datensatz in einen DataFrame und führen einige Vorverarbeitungsschritte durch:   \n",
    "\n",
    "Laden der CSV-Daten: Wir gehen davon aus, dass die Datei mushrooms.csv im Ordner data/ vorliegt (mit Header und allen Spaltennamen).      Bereinigen fehlender Werte: Einige Einträge bei stalk-root sind mit \"?\" markiert (fehlender Wert). Diese Zeilen entfernen wir aus dem Datensatz.    \n",
    "\n",
    "Kodieren der Zielvariablen: Die Spalte class enthält die Klassenbezeichnung 'e' (edible, essbar) oder 'p' (poisonous, giftig). Wir erstellen eine neue numerische Zielspalte target mit 0 für essbar und 1 für giftig.  \n",
    "    \n",
    "Optional: Features ausschließen: Standardmäßig verwenden wir alle verfügbaren Merkmale. Möchte man bestimmte Merkmale ausschließen (z. B. um den Einfluss sehr starker Prädiktoren wie odor zu untersuchen), kann man diese in einer Liste exclude_features angeben – diese würden dann aus dem DataFrame entfernt.      \n",
    "\n",
    "Train/Test-Split: Wir teilen die Daten stratifiziert in Trainings- und Testset (80/20 Aufteilung), um die Modelle anschließend unabhängig auf dem Testset bewerten zu können. Die Stratifizierung stellt sicher, dass das Verhältnis von essbaren/giftigen Pilzen in beiden Sets identisch ist.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "618d9034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datensätze geladen: 8124 Zeilen, 23 Spalten.\n",
      "Verbleibende Features: ['cap-shape', 'cap-surface', 'cap-color', 'bruises', 'odor', 'gill-attachment', 'gill-spacing', 'gill-size', 'gill-color', 'stalk-shape', 'stalk-root', 'stalk-surface-above-ring', 'stalk-surface-below-ring', 'stalk-color-above-ring', 'stalk-color-below-ring', 'veil-type', 'veil-color', 'ring-number', 'ring-type', 'spore-print-color', 'population', 'habitat']\n",
      "Klassenverteilung (target): [3488 2156]\n"
     ]
    }
   ],
   "source": [
    "# 1. Daten laden\n",
    "df = pd.read_csv('data/mushrooms.csv')\n",
    "print(f\"Datensätze geladen: {df.shape[0]} Zeilen, {df.shape[1]} Spalten.\")\n",
    "\n",
    "# 2. Bereinigen und Zielvariable kodieren\n",
    "# 2.1 Zeilen mit fehlendem Wert ('?') bei 'stalk-root' entfernen\n",
    "df = df[df['stalk-root'] != '?'].reset_index(drop=True)\n",
    "# 2.2 Zielvariable kodieren ('e'->0, 'p'->1) und in neuer Spalte 'target' speichern\n",
    "df['target'] = df['class'].map({'e': 0, 'p': 1})\n",
    "\n",
    "# 2.3 Optionale Liste starker Merkmale, die ausgeschlossen werden können\n",
    "strong_features = ['odor', 'spore-print-color', 'gill-color']\n",
    "exclude_features = []  # z.B. = strong_features, um diese zu entfernen (hier leer lassen für alle Features)\n",
    "\n",
    "if exclude_features:\n",
    "    df.drop(columns=exclude_features, inplace=True)\n",
    "    print(f\"Folgende Merkmale wurden ausgeschlossen: {exclude_features}\")\n",
    "\n",
    "# 2.4 Merkmalsmatrix X und Zielvektor y definieren\n",
    "X = df.drop(columns=['class', 'target'])\n",
    "y = df['target']\n",
    "\n",
    "print(\"Verbleibende Features:\", list(X.columns))\n",
    "print(\"Klassenverteilung (target):\", np.bincount(y))\n",
    "# Ausgabe: Verbleibende Features und Klassenverteilung\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d4de36",
   "metadata": {},
   "source": [
    "### 2. Train/Test-Split und Cross-Validation\n",
    "\n",
    "Bevor wir die verschiedenen Pipelines aufsetzen, teilen wir die Daten in Trainings- und Testmenge. Zudem definieren wir das Cross-Validation-Verfahren für die Hyperparameterabstimmung:\n",
    "\n",
    "    Train/Test-Split: 80% Training, 20% Test (stratifiziert nach der Zielvariable).\n",
    "\n",
    "    Cross-Validation (CV): Wir verwenden StratifiedKFold mit 5 Folds und shuffle=True (mit festem random_state für Reproduzierbarkeit). Dadurch wird die Trainingsmenge in 5 Teile aufgeteilt und das Training pro Hyperparameter-Kombination 5-mal mit wechselnden Validierungs-Splits durchgeführt.\n",
    "\n",
    "Diese CV-Strategie nutzen wir später in RandomizedSearchCV, um die Hyperparameter der Modelle abzustimmen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "756b8453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainingsdaten: 4515 Beispiele, Testdaten: 1129 Beispiele\n"
     ]
    }
   ],
   "source": [
    "# 3. Stratified Train/Test-Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "print(f\"Trainingsdaten: {X_train.shape[0]} Beispiele, Testdaten: {X_test.shape[0]} Beispiele\")\n",
    "\n",
    "# 4. Cross-Validation Setup (5-fold Stratified)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e9d1b4",
   "metadata": {},
   "source": [
    "### 3. Definition verschiedener Encoder und Pipeline-Komponenten\n",
    "\n",
    "Bevor wir die eigentlichen Modelle trainieren, bereiten wir für jede Encodierungsstrategie einen Transformationsschritt vor. Alle Encoder sollen nur auf die kategorischen Spalten (hier: alle Merkmale in X) angewandt werden. Anschließend kombinieren wir diese Encoder mit den jeweiligen Modellen in Scikit-Learn Pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17485684",
   "metadata": {},
   "source": [
    "#### 3.1 Ordinal Encoder\n",
    "\n",
    "OrdinalEncoder: Dieser Encoder wandelt kategorische Werte in nummerische Labels um (0, 1, 2, ...). Dabei wird keine besondere Ordnung der Kategorien angenommen, außer man gibt sie explizit vor. Für Features mit echter ordinaler Bedeutung (wie ring-number: none, one, two) kann man die Reihenfolge der Kategorien so angeben, dass die Zahlenwerte der natürlichen Rangfolge entsprechen. Bei nominalen Features hingegen gibt es keine natürliche Reihenfolge – in solchen Fällen nutzt der OrdinalEncoder intern alphabetische Sortierung der Werte, was dem Modell aber eine willkürliche Ordnung suggeriert.\n",
    "\n",
    "Vorteil: Sparsam (es entsteht nur eine Spalte pro Feature). Nachteil: Bei nominalen Kategorien kann das Modell fälschlicherweise eine lineare Rangordnung interpretieren; für lineare Modelle kann dies ungeeignet sein, während Baum-Modelle damit oft umgehen können (sie können die integer-Codes wie Kategorien behandeln, wenn auch ohne explizites Verständnis der Unterschiedlichkeit).\n",
    "\n",
    "Wir wenden den OrdinalEncoder auf alle verbliebenen kategorialen Spalten an. Unbekannte Kategorien (falls im Testset welche auftreten sollten) werden auf einen speziellen Wert (-1) gemappt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0c91162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kategoriale Spaltenliste (hier: alle Spalten von X_train)\n",
    "categorical_cols = X_train.columns.tolist()\n",
    "\n",
    "# OrdinalEncoder vorbereiten (unbekannte Kategorien -> -1)\n",
    "ordinal_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "ord_preprocessor = ColumnTransformer(\n",
    "    transformers=[('ord', ordinal_encoder, categorical_cols)],\n",
    "    remainder='drop'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631be2ee",
   "metadata": {},
   "source": [
    "#### 3.2 One-Hot Encoder\n",
    "\n",
    "OneHotEncoder: Dieser Encoder erstellt für jede Kategorie eines Features eine eigene Dummy-Spalte mit 0/1-Codierung. Ein Beispiel: Ein Merkmal cap-color mit Werten {red, yellow, green, ...} würde z. B. in mehrere Spalten cap-color_red, cap-color_yellow, cap-color_green, ... umgewandelt. Der Wert 1 steht dann für das Vorhandensein der jeweiligen Kategorie.\n",
    "\n",
    "Vorteil: Es entsteht keine falsche ordinale Beziehung zwischen Kategorien, da jedes Kategorie-Label separat behandelt wird. Modelle (insbesondere lineare Modelle) können so für jede Kategorie einen eigenen Parameter lernen. Nachteil: Bei vielen Kategorien pro Feature oder vielen Features insgesamt steigt die Dimension des Feature-Vektors stark an (Fluch der Dimensionalität). Zudem entstehen viele dünn besetzte (spärliche) Features.\n",
    "\n",
    "Wir nutzen den OneHotEncoder von Scikit-Learn. Parameter handle_unknown='ignore' sorgt dafür, dass unbekannte Kategorien (im Test) ignoriert werden (statt Fehler zu werfen). Wir fordern ein dichtes Ausgabeformat (sparse_output=False), um es kompatibel mit den Pipeline-Schritten (z. B. Feature-Selection, StandardScaler) zu machen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8082d9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "ohe_preprocessor = ColumnTransformer(\n",
    "    transformers=[('onehot', onehot_encoder, categorical_cols)],\n",
    "    remainder='drop'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fcb586",
   "metadata": {},
   "source": [
    "#### 3.3 Binary Encoder\n",
    "\n",
    "Binary Encoding: Dies ist ein alternatives Kodierungsverfahren (nicht direkt in Scikit-Learn enthalten, aber über Category Encoders Bibliothek oder eigene Implementierung möglich). Dabei wird jede Kategorie zunächst einem eindeutigen integer Code zugewiesen (ähnlich wie Ordinal-Encoding, aber ohne implizite Ordnung). Anschließend wird dieser Code im binären Zahlensystem dargestellt, und jede Bitstelle wird zu einem eigenen binären Feature.\n",
    "\n",
    "Beispiel: Hat ein Feature 5 Kategorien, werden 3 Bits benötigt (weil 2^3 = 8 ≥ 5). Angenommen die Kategorien A, B, C, D, E bekommen Codes 0,1,2,3,4. Diese werden binär: A=000, B=001, C=010, D=011, E=100. Dann entstehen 3 neue Spalten (Bit0, Bit1, Bit2), die je nach Kategorie mit 0/1 gefüllt werden. So teilen sich Kategorien gewisse Bits, was die Dimension stark reduziert (nur log2(N) Spalten pro Feature, statt N bei One-Hot). Nachteil: Die Interpretation der einzelnen Bits ist schwieriger, und es können Kollisionen auftreten: Zwei verschiedene Kategorien können in manchen Bits gleiche Werte haben. Lineare Modelle können dann Kategorien nicht vollständig auseinanderhalten (nicht linear separabel im Bit-Raum), während Baum-Modelle mit Kombinationen von Bit-Spalten ggf. umgehen können.\n",
    "\n",
    "Wir implementieren einen einfachen Binary Encoder selbst und verwenden ihn für alle kategorialen Spalten. (Bei sehr hoher Kardinalität könnte alternativ ein Hashing-Trick verwendet werden, der ähnlich funktioniert, aber randomisierte Kollisionen einführt.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feda8589",
   "metadata": {},
   "source": [
    "Wir haben den BinaryEncoder so gestaltet, dass er unbekannte Kategorien zur Not mit einem neuen Code versieht. Allerdings kann dies dazu führen, dass zur Laufzeit ein zusätzliches Bit nötig wäre, was in unserer Implementierung nur dynamisch (zur Not) berücksichtigt wird. In unserem Datensatz erwarten wir keine völlig neuen Kategorien im Testset, daher sollte dieser Fall nicht eintreten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9356f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Eigene Implementierung des Binary Encoding für kategoriale Features.\"\"\"\n",
    "    def __init__(self, cols=None):\n",
    "        self.cols = cols  # zu kodierende Spalten\n",
    "        self.category_maps = {}  # speichert Mapping von Kategorie -> Code je Spalte\n",
    "        self.n_bits = {}         # Anzahl benötigter Bits je Spalte\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Falls X ein DataFrame ist, kopieren; sonst in DataFrame umwandeln\n",
    "        df = pd.DataFrame(X).copy()\n",
    "        if self.cols is None:\n",
    "            self.cols = df.columns.tolist()\n",
    "        for col in self.cols:\n",
    "            # Eindeutige Kategorien sammeln und Code zuweisen (0,1,2,...)\n",
    "            unique_vals = sorted(df[col].unique())\n",
    "            mapping = {val: idx for idx, val in enumerate(unique_vals)}\n",
    "            self.category_maps[col] = mapping\n",
    "            # Benötigte Bit-Anzahl für diese Spalte berechnen\n",
    "            n_cat = len(unique_vals)\n",
    "            # Mindestens 1 Bit, auch wenn nur 1 Kategorie (Edge-Case)\n",
    "            bits = 1 if n_cat <= 1 else math.ceil(math.log2(n_cat))\n",
    "            self.n_bits[col] = bits\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        df = pd.DataFrame(X).copy()\n",
    "        encoded_cols = []  # sammeln die kodierten Bit-Spalten als Series\n",
    "        for col in self.cols:\n",
    "            # Verwende gelerntes Mapping; unbekannte Werte bekommen Code = n_cat (neuer höchster Code)\n",
    "            mapping = self.category_maps[col]\n",
    "            n_cat = len(mapping)\n",
    "            codes = df[col].apply(lambda val: mapping.get(val, n_cat)).astype(int)\n",
    "            bits = self.n_bits[col]\n",
    "            # Falls unbekannte Kategorie einen zusätzlichen Bit benötigt (selten), erhöhe Bits dynamisch\n",
    "            if codes.max() >= (1 << bits):\n",
    "                bits += 1\n",
    "                self.n_bits[col] = bits\n",
    "            # Erzeuge die Bit-Spalten\n",
    "            for i in range(bits):\n",
    "                bit_col = (codes >> i) & 1  # Bit i extrahieren\n",
    "                bit_col.name = f\"{col}_bit{i}\"\n",
    "                encoded_cols.append(bit_col)\n",
    "        # Konkatenieren der Bit-Spalten zu einem DataFrame und als numpy zurückgeben\n",
    "        encoded_df = pd.concat(encoded_cols, axis=1)\n",
    "        return encoded_df.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a35b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Hyperparameter-Suchräume und Ergebnis-Container\n",
    "\n",
    "rf_param_dist = {\n",
    "    'clf__n_estimators': np.random.randint(50, 500, size=30),\n",
    "    'clf__max_depth': [None] + list(np.random.randint(5, 50, size=5)),\n",
    "    'clf__min_samples_split': np.random.randint(2, 20, size=10),\n",
    "    'clf__max_features': [None, 'sqrt', 'log2']\n",
    "}\n",
    "lr_param_dist = {\n",
    "    'clf__C': np.random.uniform(0.001, 10, size=20),\n",
    "    'clf__penalty': ['l2', 'l1'],\n",
    "    'clf__solver': ['saga']\n",
    "}\n",
    "\n",
    "best_models = {}\n",
    "results_summary = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cc9a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Encoding: OrdinalEncoder #####\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Done Ordinal\n"
     ]
    }
   ],
   "source": [
    "# ##### Encoding: OrdinalEncoder #####\n",
    "print(\"##### Encoding: OrdinalEncoder #####\")\n",
    "\n",
    "# RF-Suche\n",
    "ord_rf_search = RandomizedSearchCV(\n",
    "    Pipeline([\n",
    "        ('enc', ord_preprocessor),\n",
    "        ('clf', RandomForestClassifier(random_state=42))\n",
    "    ]),\n",
    "    rf_param_dist, n_iter=30, cv=cv, scoring='accuracy',\n",
    "    n_jobs=-1, random_state=42, verbose=1\n",
    ")\n",
    "ord_rf_search.fit(X_train, y_train)\n",
    "y_pred_ord_rf = ord_rf_search.predict(X_test)\n",
    "\n",
    "# LR-Suche\n",
    "ord_lr_search = RandomizedSearchCV(\n",
    "    Pipeline([\n",
    "        ('enc', ord_preprocessor),\n",
    "        ('scale', StandardScaler(with_mean=False)),\n",
    "        ('clf', LogisticRegression(max_iter=10000, random_state=42))\n",
    "    ]),\n",
    "    lr_param_dist, n_iter=20, cv=cv, scoring='accuracy',\n",
    "    n_jobs=-1, random_state=42, verbose=1\n",
    ")\n",
    "ord_lr_search.fit(X_train, y_train)\n",
    "y_pred_ord_lr = ord_lr_search.predict(X_test)\n",
    "\n",
    "# Ergebnisse speichern – hier die korrekte Zuordnung von Modell-Objekt und Name\n",
    "for model_name, search_obj, y_pred in [\n",
    "    ('RandomForest', ord_rf_search, y_pred_ord_rf),\n",
    "    ('LogisticRegression', ord_lr_search, y_pred_ord_lr)\n",
    "]:\n",
    "    best_models[('Ordinal', model_name)] = search_obj.best_estimator_\n",
    "    results_summary.append({\n",
    "        'Encoder': 'Ordinal',\n",
    "        'Model': model_name,\n",
    "        'Train Accuracy': search_obj.score(X_train, y_train),\n",
    "        'Test Accuracy': search_obj.score(X_test, y_test),\n",
    "        'ROC-AUC': roc_auc_score(y_test, search_obj.predict_proba(X_test)[:,1])\n",
    "    })\n",
    "\n",
    "print(\"Done Ordinal\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b042f21e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Encoding: OneHotEncoder #####\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    }
   ],
   "source": [
    "# 3) OneHotEncoder + RandomForest und LogisticRegression\n",
    "print(\"##### Encoding: OneHotEncoder #####\")\n",
    "\n",
    "# Random Forest mit OneHot\n",
    "ohe_rf_pipe = Pipeline([\n",
    "    ('enc', ohe_preprocessor),\n",
    "    ('feature_sel', SelectFromModel(RandomForestClassifier(random_state=42), threshold='median')),\n",
    "    ('clf', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "ohe_rf_search = RandomizedSearchCV(\n",
    "    ohe_rf_pipe, rf_param_dist,\n",
    "    n_iter=30, cv=cv, scoring='accuracy',\n",
    "    n_jobs=-1, random_state=42, verbose=1\n",
    ")\n",
    "ohe_rf_search.fit(X_train, y_train)\n",
    "y_pred_ohe_rf = ohe_rf_search.predict(X_test)\n",
    "\n",
    "# Logistic Regression mit OneHot\n",
    "ohe_lr_pipe = Pipeline([\n",
    "    ('enc', ohe_preprocessor),\n",
    "    ('scale', StandardScaler(with_mean=False)),\n",
    "    ('clf', LogisticRegression(max_iter=10000, random_state=42))\n",
    "])\n",
    "ohe_lr_search = RandomizedSearchCV(\n",
    "    ohe_lr_pipe, lr_param_dist,\n",
    "    n_iter=20, cv=cv, scoring='accuracy',\n",
    "    n_jobs=-1, random_state=42, verbose=1\n",
    ")\n",
    "ohe_lr_search.fit(X_train, y_train)\n",
    "y_pred_ohe_lr = ohe_lr_search.predict(X_test)\n",
    "\n",
    "# Ergebnisse speichern\n",
    "for model_name, search_obj, y_pred in [\n",
    "    ('RandomForest', ohe_rf_search, y_pred_ohe_rf),\n",
    "    ('LogisticRegression', ohe_lr_search, y_pred_ohe_lr)\n",
    "]:\n",
    "    best_models[('OneHot', model_name)] = search_obj.best_estimator_\n",
    "    results_summary.append({\n",
    "        'Encoder': 'OneHot',\n",
    "        'Model': model_name,\n",
    "        'Train Accuracy': search_obj.score(X_train, y_train),\n",
    "        'Test Accuracy': search_obj.score(X_test, y_test),\n",
    "        'ROC-AUC': roc_auc_score(y_test, search_obj.predict_proba(X_test)[:,1])\n",
    "    })\n",
    "\n",
    "print(\"Done OneHot\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b576104a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4a) Fixed BinaryEncoder\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class BinaryEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cols=None):\n",
    "        self.cols = cols\n",
    "        self.category_maps = {}\n",
    "        self.n_bits = {}\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        df = pd.DataFrame(X, columns=self.cols)\n",
    "        for col in self.cols:\n",
    "            vals = sorted(df[col].unique())\n",
    "            mapping = {v: i for i,v in enumerate(vals)}\n",
    "            self.category_maps[col] = mapping\n",
    "            bits = max(1, int(np.ceil(np.log2(len(vals)))))\n",
    "            self.n_bits[col] = bits\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        df = pd.DataFrame(X, columns=self.cols)\n",
    "        encoded = []\n",
    "        for col in self.cols:\n",
    "            mapping = self.category_maps[col]\n",
    "            default = len(mapping)\n",
    "            codes = df[col].map(mapping).fillna(default).astype(int).values  # numpy array\n",
    "            bits = self.n_bits[col]\n",
    "            # Bit-Extraktion auf Numpy-Array\n",
    "            for i in range(bits):\n",
    "                encoded.append(((codes >> i) & 1).reshape(-1,1))\n",
    "        return np.hstack(encoded)\n",
    "\n",
    "# 4b) Pipelines mit BinaryEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "print(\"##### Encoding: BinaryEncoder #####\")\n",
    "\n",
    "bin_rf_pipe = Pipeline([\n",
    "    ('enc', BinaryEncoder(cols=categorical_cols)),\n",
    "    ('feature_sel', SelectFromModel(RandomForestClassifier(random_state=42), threshold='median')),\n",
    "    ('clf', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "bin_rf_search = RandomizedSearchCV(bin_rf_pipe, rf_param_dist,\n",
    "                                   n_iter=30, cv=cv, scoring='accuracy',\n",
    "                                   n_jobs=-1, random_state=42, verbose=1)\n",
    "bin_rf_search.fit(X_train, y_train)\n",
    "y_pred_bin_rf = bin_rf_search.predict(X_test)\n",
    "\n",
    "bin_lr_pipe = Pipeline([\n",
    "    ('enc', BinaryEncoder(cols=categorical_cols)),\n",
    "    ('scale', StandardScaler(with_mean=False)),\n",
    "    ('clf', LogisticRegression(max_iter=10000, random_state=42))\n",
    "])\n",
    "bin_lr_search = RandomizedSearchCV(bin_lr_pipe, lr_param_dist,\n",
    "                                   n_iter=20, cv=cv, scoring='accuracy',\n",
    "                                   n_jobs=-1, random_state=42, verbose=1)\n",
    "bin_lr_search.fit(X_train, y_train)\n",
    "y_pred_bin_lr = bin_lr_search.predict(X_test)\n",
    "\n",
    "for name, search, y_pred in [\n",
    "    ('Binary','RandomForest', y_pred_bin_rf),\n",
    "    ('Binary','LogisticRegression', y_pred_bin_lr)\n",
    "]:\n",
    "    est = bin_rf_search.best_estimator_ if 'Forest' in name else bin_lr_search.best_estimator_\n",
    "    best_models[( 'Binary', name )] = est\n",
    "    results_summary.append({\n",
    "        'Encoder': 'Binary',\n",
    "        'Model': name,\n",
    "        'Train Accuracy': search.score(X_train, y_train),\n",
    "        'Test Accuracy': search.score(X_test, y_test),\n",
    "        'ROC-AUC': roc_auc_score(y_test, search.predict_proba(X_test)[:,1])\n",
    "    })\n",
    "\n",
    "print(\"Done Binary\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f0ea29",
   "metadata": {},
   "source": [
    "#### 5. Auswertung der Ergebnisse\n",
    "\n",
    "Nachdem alle Modelle trainiert und getestet sind, vergleichen wir die Performance der verschiedenen Ansätze. Wir betrachten vor allem:\n",
    "\n",
    "    Genauigkeit (Accuracy) auf dem Testset und ggf. auf dem Trainset, um Overfitting abzuschätzen.\n",
    "\n",
    "    ROC-AUC auf dem Testset.\n",
    "\n",
    "    Konfusionsmatrizen für einen anschaulichen Vergleich der Fehlklassifikationen.\n",
    "\n",
    "    ROC-Kurven für einen visuellen Vergleich der Modelle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742f2d0d",
   "metadata": {},
   "source": [
    "5.1 Performance-Vergleich in Tabellenform\n",
    "\n",
    "Wir fassen die Ergebnisse in einer Tabelle zusammen:\n",
    "\n",
    "Die Spalte Overfit_gap zeigt die Differenz zwischen Trainings- und Test-Accuracy (ein hoher Wert deutet auf Overfitting hin, da das Modell deutlich besser auf den Trainingsdaten performt als auf neuen Daten)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e2733b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ergebnisse in DataFrame umwandeln und ausgeben\n",
    "results_df = pd.DataFrame(results_summary)\n",
    "results_df['Overfit_gap'] = results_df['Train Accuracy'] - results_df['Test Accuracy']\n",
    "results_df = results_df.sort_values(['Encoder','Model']).reset_index(drop=True)\n",
    "results_df[['Encoder', 'Model', 'Train Accuracy', 'Test Accuracy', 'ROC-AUC', 'Overfit_gap']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db100aaa",
   "metadata": {},
   "source": [
    "5.2 Konfusionsmatrizen\n",
    "\n",
    "Wir visualisieren die Konfusionsmatrix für jedes Modell, um zu sehen, welche Fehler gemacht wurden (False Positives vs. False Negatives):\n",
    "\n",
    "Anhand der Konfusionsmatrizen können wir z.B. erkennen, ob ein Modell vor allem einen der beiden Klassen systematisch falsch klassifiziert (z.B. ob essbare Pilze irrtümlich als giftig markiert werden oder umgekehrt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1d71af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konfusionsmatrix Plot-Funktion für Kürze\n",
    "def plot_confusion(model_key, y_true, y_pred):\n",
    "    enc, mod = model_key\n",
    "    disp = ConfusionMatrixDisplay.from_predictions(\n",
    "        y_true, y_pred, display_labels=['edible','poisonous'], cmap=plt.cm.Blues, normalize=None\n",
    "    )\n",
    "    disp.ax_.set_title(f\"Confusion Matrix: {enc} + {mod}\")\n",
    "    plt.show()\n",
    "\n",
    "# Für jede Kombination die Konfusionsmatrix anzeigen\n",
    "plot_confusion(('Ordinal','RandomForest'), y_test, y_pred_ord_rf)\n",
    "plot_confusion(('Ordinal','LogisticRegression'), y_test, y_pred_ord_lr)\n",
    "plot_confusion(('OneHot','RandomForest'), y_test, y_pred_ohe_rf)\n",
    "plot_confusion(('OneHot','LogisticRegression'), y_test, y_pred_ohe_lr)\n",
    "plot_confusion(('Binary','RandomForest'), y_test, y_pred_bin_rf)\n",
    "plot_confusion(('Binary','LogisticRegression'), y_test, y_pred_bin_lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1d0c96",
   "metadata": {},
   "source": [
    "5.3 ROC-Kurven\n",
    "\n",
    "Abschließend vergleichen wir die ROC-Kurven der Modelle. Um die Übersicht zu bewahren, plotten wir die ROC-Kurven gruppiert nach Modelltyp:\n",
    "\n",
    "    ROC-Kurven der drei Encodings für Random Forest in einem Plot.\n",
    "\n",
    "    ROC-Kurven der drei Encodings für Logistic Regression in einem separaten Plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cdf6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC-Kurven für Random Forest mit verschiedenen Encodern\n",
    "plt.figure(figsize=(6,5))\n",
    "RocCurveDisplay.from_estimator(ord_rf_search.best_estimator_, X_test, y_test, name=\"RF - Ordinal\")\n",
    "RocCurveDisplay.from_estimator(ohe_rf_search.best_estimator_, X_test, y_test, name=\"RF - OneHot\")\n",
    "RocCurveDisplay.from_estimator(bin_rf_search.best_estimator_, X_test, y_test, name=\"RF - Binary\")\n",
    "plt.plot([0,1],[0,1],'k--')  # Diagonale\n",
    "plt.title(\"ROC Curve - Random Forest (alle Encodings)\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# ROC-Kurven für Logistic Regression mit verschiedenen Encodern\n",
    "plt.figure(figsize=(6,5))\n",
    "RocCurveDisplay.from_estimator(ord_lr_search.best_estimator_, X_test, y_test, name=\"LR - Ordinal\")\n",
    "RocCurveDisplay.from_estimator(ohe_lr_search.best_estimator_, X_test, y_test, name=\"LR - OneHot\")\n",
    "RocCurveDisplay.from_estimator(bin_lr_search.best_estimator_, X_test, y_test, name=\"LR - Binary\")\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.title(\"ROC Curve - Logistic Regression (alle Encodings)\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27e4246",
   "metadata": {},
   "source": [
    "6. Ergebnisse und Beobachtungen\n",
    "\n",
    "(In diesem Abschnitt fassen wir die wichtigsten Erkenntnisse zusammen. Bitte führen Sie die obigen Zellen aus, um die tatsächlichen Ergebnisse zu erhalten. Anschließend können Sie hier die Resultate interpretieren.)\n",
    "\n",
    "    Accuracy und ROC-AUC: Im Vergleich zeigt sich, dass ... [hier die Werte aus results_df diskutieren]. Möglicherweise erreichen alle Modelle sehr hohe Genauigkeiten (nahe 100%), was darauf hindeutet, dass der Datensatz sehr leicht trennbar ist (insbesondere Merkmale wie odor tragen stark zur Vorhersage bei). Falls alle Ansätze 100% erreichen, liegt das daran, dass der Datensatz linearly separable bzw. durch einfache Entscheidungsregeln perfekt aufteilbar ist – in der Tat ist bekannt, dass bestimmte Geruchswerte ausschließlich bei giftigen Pilzen vorkommen, wodurch eine fehlerfreie Trennung möglich ist.\n",
    "\n",
    "    Vergleich Encoder: Für den Random Forest macht der Encodierungsansatz tendenziell weniger Unterschied. Der Random Forest mit One-Hot und mit Binary Encoding sollte ähnlich performen, da beide dem Baum erlauben, jede Kategorie separat zu behandeln (Binary Encoding erfordert evtl. Kombination von Bit-Splits, aber tiefe Bäume können das umsetzen). Der OrdinalEncoder kann ebenfalls gut funktionieren, da der Random Forest die numerischen Codes nicht linear interpretieren muss – er kann z.B. an kodierten Werten Schwellen anlegen, die einzelnen Kategorien (oder Gruppen davon) entsprechen. Dennoch könnte One-Hot den leichtesten Zugang bieten, da jede Kategorie explizit ist.\n",
    "\n",
    "    Bei der Logistic Regression sind Unterschiede wahrscheinlicher: Die One-Hot-Codierung ermöglicht dem Modell, für jede Kategorie einen separaten Koeffizienten zu lernen, was sehr flexibel ist. Die Ordinal-Codierung dagegen zwingt das Modell, eine monotone Beziehung der Kategorien zur Zielvariablen anzunehmen – dies kann zu suboptimaler Performance führen, wenn Kategorien nominal sind. Die Binary-Codierung liegt dazwischen: Sie bietet mehrere Bit-Features, die das Modell kombinieren kann, um Kategorien zu unterscheiden. In den Ergebnissen könnte man sehen, dass z.B. die Logistic Regression mit One-Hot alle giftigen Pilze korrekt erkennt, während mit Ordinal-Encoding eventuell einige Fehler passieren (weil die lineare Entscheidungsgrenze im ordinal kodierten Raum nicht optimal passt).\n",
    "\n",
    "    Overfitting: Um Overfitting zu beurteilen, schauen wir auf Overfit_gap bzw. vergleichen die Trainings- und Test-Accuracy. Idealerweise sollten diese nahe beieinander liegen. Wenn ein Modell auf dem Training deutlich besser ist als auf dem Test (große Lücke), deutet das auf Overfitting hin. In unserem Fall, falls alle Modelle nahezu 100% auf Test erreichen, ist Overfitting kein großes Problem (eher Underfitting bei schlechterer Performance auf Test). Sollten wir jedoch die starken Features (wie odor) entfernen, würde der Task schwieriger und Overfitting-Tendenzen könnten sichtbar werden – z.B. könnte der Random Forest mit One-Hot dann auf dem Training 100% erreichen, aber auf dem Test weniger, was eine Überanpassung an idiosynkratische Kombinationen andeutet. In der aktuellen Einstellung mit allen Features erwarten wir, dass sowohl Random Forest als auch Logistic Regression durch die informativen Features sehr gute Generalisierung zeigen.\n",
    "\n",
    "    Konfusionsmatrix: Die Konfusionsmatrizen zeigen, wie die Fehlklassifikationen verteilt sind. Wenn ein Modell perfomt (keine Fehler), erscheinen nur Einträge auf der Diagonalen. Sollten Fehler auftreten, ist zu prüfen, ob es z.B. mehr false negatives (giftige Pilze irrtümlich als essbar eingestuft) oder false positives gibt. Ersteres wäre kritischer (man möchte keine giftigen übersehen). Bei gutem Modell sollten beide Fehlertypen minimal sein. Wir beobachten … [Diskussion der Matrix z.B.: Logistic mit Ordinal hatte vielleicht ein paar Fehlklassifikationen].\n",
    "\n",
    "    ROC-Kurven: Die ROC-Kurven geben weitere Einblicke, insbesondere falls die Modelle nicht alle perfekt sind. Man kann sehen, dass ... [Interpretation der Kurven: liegen alle nah am linken oberen Eck = ausgezeichnete Modelle; falls Unterschiede, welche Kurve dominiert]. Oft sind Random Forest und Logistic mit One-Hot sehr konkurrenzfähig. Wenn Unterschiede bestehen, könnte der Random Forest etwas besser mit bestimmten Encodings umgehen.\n",
    "\n",
    "Fazit: Durch diesen Vergleich haben wir gesehen, dass die Wahl des Encoders vor allem für lineare Modelle (wie Logistic Regression) kritisch ist, während ein leistungsfähiges nicht-lineares Modell wie Random Forest mit allen Kodierungen gut zurechtkommt. Bei nominalen Kategorien empfiehlt sich One-Hot-Encoding oder geeignete alternative Kodierungen, um dem Modell die nötige Flexibilität zu geben. Der Mushroom-Datensatz ist so informativ, dass selbst einfache Modelle bei richtiger Kodierung nahezu perfekte Ergebnisse liefern können. Dennoch ist es wichtig, Overfitting zu überwachen – in komplexeren Datenszenarien müsste man bei sehr hohen Trainingsscores und deutlich niedrigeren Testscores eingreifen (z.B. durch Feature Selection, Regularisierung oder mehr Daten). In unserem Fall sind Training und Test Performance ähnlich hoch, was auf eine gute Generalisierung hindeutet. Viel Erfolg beim weiteren Experimentieren mit der Pipeline!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
