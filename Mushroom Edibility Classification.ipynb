{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dimensional-external",
   "metadata": {},
   "source": [
    "# Mushroom Edibility Classification\n",
    "\n",
    "**Link**\n",
    "\n",
    "https://www.kaggle.com/uciml/mushroom-classification\n",
    "\n",
    "**Context**\n",
    "\n",
    "Although this dataset was originally contributed to the UCI Machine Learning repository nearly 30 years ago, mushroom hunting (otherwise known as \"shrooming\") is enjoying new peaks in popularity. Learn which features spell certain death and which are most palatable in this dataset of mushroom characteristics. And how certain can your model be?\n",
    "\n",
    "**Content**\n",
    "\n",
    "This dataset includes descriptions of hypothetical samples corresponding to 23 species of gilled mushrooms in the Agaricus and Lepiota Family Mushroom drawn from The Audubon Society Field Guide to North American Mushrooms (1981). Each species is identified through the target attribute `class` as definitely edible, definitely poisonous, or of unknown edibility and not recommended. This latter class was combined with the poisonous one.\n",
    "\n",
    "The dataset consists of the following attributes:\n",
    "- class - edible=e, poisonous=p\n",
    "- cap-shape: bell=b,conical=c,convex=x,flat=f, knobbed=k,sunken=s\n",
    "- cap-surface: fibrous=f,grooves=g,scaly=y,smooth=s\n",
    "- cap-color: brown=n,buff=b,cinnamon=c,gray=g,green=r,pink=p,purple=u,red=e,white=w,yellow=y\n",
    "- bruises: bruises=t,no=f\n",
    "- odor: almond=a,anise=l,creosote=c,fishy=y,foul=f,musty=m,none=n,pungent=p,spicy=s\n",
    "- gill-attachment: attached=a,descending=d,free=f,notched=n\n",
    "- gill-spacing: close=c,crowded=w,distant=d\n",
    "- gill-size: broad=b,narrow=n\n",
    "- gill-color: black=k,brown=n,buff=b,chocolate=h,gray=g, green=r,orange=o,pink=p,purple=u,red=e,white=w,yellow=y\n",
    "- stalk-shape: enlarging=e,tapering=t\n",
    "- stalk-root: bulbous=b,club=c,cup=u,equal=e,rhizomorphs=z,rooted=r,missing=?\n",
    "- stalk-surface-above-ring: fibrous=f,scaly=y,silky=k,smooth=s\n",
    "- stalk-surface-below-ring: fibrous=f,scaly=y,silky=k,smooth=s\n",
    "- stalk-color-above-ring: brown=n,buff=b,cinnamon=c,gray=g,orange=o,pink=p,red=e,white=w,yellow=y\n",
    "- stalk-color-below-ring: brown=n,buff=b,cinnamon=c,gray=g,orange=o,pink=p,red=e,white=w,yellow=y\n",
    "- veil-type: partial=p,universal=u\n",
    "- veil-color: brown=n,orange=o,white=w,yellow=y\n",
    "- ring-number: none=n,one=o,two=t\n",
    "- ring-type: cobwebby=c,evanescent=e,flaring=f,large=l,none=n,pendant=p,sheathing=s,zone=z\n",
    "- spore-print-color: black=k,brown=n,buff=b,chocolate=h,green=r,orange=o,purple=u,white=w,yellow=y\n",
    "- population: abundant=a,clustered=c,numerous=n,scattered=s,several=v,solitary=y\n",
    "- habitat: grasses=g,leaves=l,meadows=m,paths=p,urban=u,waste=w,woods=d\n",
    "\n",
    "**Task (Classification)**\n",
    "\n",
    "Your task is to use the present data set to predict the edibility of a mushroom sample. To do this, use the `Logistic Regression` and `XGBoost` methods for this task. You must also include a third method that you have selected yourself.\n",
    "\n",
    "First of all, get an overview of the project in your group. Then carefully read the checklist for machine learning projects and think about how you want to organize your group work. It is strongly recommended that all task items are completed by all group members. You can divide the focus among yourself, but make sure that all members are as well informed as possible about the content.\n",
    "\n",
    "Use the checklist for machine learning projects as a guide when working on the task. Document all the individual steps that are listed there (main and sub-items). Make sure to use Markdown Cells for your documentation. Document the functionality of your algorithms (all three) with equations and explanations. Dont forget, this project is a task for five students. We expect a detailed documentation of your approach and your results.\n",
    "\n",
    "**Note**\n",
    "\n",
    "We are aware that there are examples and solutions for the selected data sets on popular platforms, e.g. Kaggle. You are welcome to use them as a guide. But remember that at the end of the project, your own work will be assessed. We compare the results with the popular solutions of common platforms. We would like to recognize the independence in your work and see a difference to the existing solution approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annual-estimate",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb51306a",
   "metadata": {},
   "source": [
    "**ML Project Checklist**\n",
    "1. Frame the problem and look at the big picture. \n",
    "2. Get the data. \n",
    "3. Explore the data to gain insights. \n",
    "4. Prepare the data to better expose the underlying data patterns to Machine Learning algorithms. \n",
    "5. Explore many different models and short-list the best ones. \n",
    "6. Fine-tune your models and combine them into a great solution. \n",
    "7. Present your solution. \n",
    "8. Launch, monitor, and maintain your system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43601c5",
   "metadata": {},
   "source": [
    "# 1. Framing the problem\n",
    "\n",
    "The primary objective of this project is to estimate the probability that a given mushroom sample is edible, based on various features such as gill size, cap color, and other morphological characteristics. The resulting machine learning models could potentially be integrated into a broader \"mushroom guidance\" application. In such an app, users could take a photo of a mushroom, and the system would provide an initial estimate of its edibility. This approach frames the problem as a supervised learning classification task, where performance can be measured using metrics such as accuracy, precision, and recall. Given the real-world risk of misclassification, particular attention must be paid to minimizing false positives (i.e., predicting a poisonous mushroom as edible). While a reliable system would need to exceed a defined accuracy threshold to be considered practical, the aim of this project is to assess feasibility.\n",
    "Nonetheless, real-life expertise should not be disregarded. The application could also support experts by providing a second opinion, comparable to how machine learning assists doctors with diagnostics in fields like radiology. This hybrid approach (combining expert knowledge with algorithmic estimation) could lead to more robust and safer classification outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e210fc2",
   "metadata": {},
   "source": [
    "# 2. Getting the data\n",
    " \n",
    "The data has been downloaded and stored in CSV format to facilitate loading and manipulation within standard data science tools such as Pandas. A copy from the original data was created to perform the following data analysis and model training steps on.\n",
    "\n",
    "**Außerdem zu erwähnen**:\n",
    "- mussten manche Daten hinzugefügt werden weil \"?\"- oder \"NaN\"-Eintrag ?\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da1cf45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### LIBRARIES ###\n",
    "\n",
    "# ─── Standard ────────────────────────────────────────────────────────\n",
    "import math\n",
    "from typing import List, Optional\n",
    "\n",
    "# ─── Data Handling ───────────────────────────────────────────────────\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ─── Visualization ───────────────────────────────────────────────────\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns   \n",
    "\n",
    "# ─── Preprocessing & Pipeline ────────────────────────────────────────\n",
    "from scipy.stats import chi2_contingency\n",
    "from itertools import combinations\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import (\n",
    "    OneHotEncoder,\n",
    "    OrdinalEncoder,\n",
    "    LabelEncoder,\n",
    "    StandardScaler\n",
    ")\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# ─── Modelle & Hyperparameter-Tuning ─────────────────────────────────\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    StratifiedKFold,\n",
    "    RandomizedSearchCV\n",
    ")\n",
    "\n",
    "# ─── Metrics ─────────────────────────────────────────────────────────\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    roc_auc_score,\n",
    "    ConfusionMatrixDisplay,\n",
    "    RocCurveDisplay\n",
    ")\n",
    "\n",
    "# ─── Encoder / Transformer ───────────────────────────────────────────\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "# from category_encoders import BinaryEncoder  # falls du die Bibliothek nutzt\n",
    "# oder definiere hier deinen eigenen BinaryEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3edab390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rohdaten: 8124 Zeilen, 23 Spalten\n"
     ]
    }
   ],
   "source": [
    "df_raw = pd.read_csv(r'data/mushrooms.csv')\n",
    "print(f\"Rohdaten: {df_raw.shape[0]} Zeilen, {df_raw.shape[1]} Spalten\")\n",
    "\n",
    "# create copies of the original DataFrame\n",
    "df = df_raw.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae22c17",
   "metadata": {},
   "source": [
    "# 3. Exploring the data\n",
    "\n",
    "\n",
    "The dataset, sourced from the UCI Machine Learning Repository, consists of 8,124 complete samples with no missing values. It includes 23 categorical features, each representing a specific characteristic of mushrooms, such as cap-shape, odor, veil-color, and habitat. All variables are categorical, with varying cardinality: while some, like the target variable edibility, are binary, others, such as gill-color, contain more than 10 distinct categories. \n",
    "\n",
    "General guidelines:\n",
    "- Create a copy of the data for exploration (down sampling if necessary).\n",
    "- Keep record of your data exploration (Jupyter notebook).\n",
    "- Study each attribute and its characteristics: \n",
    "    Name, Type (categorical, int/float, bounded/unbounded, text, structured, etc.), % missing values, Noisiness (stochastic, outliers, rounding errors, etc.), \n",
    "    Type of distribution (Gaussian, uniform, logarithmic, etc.), Possibly useful for the task?\n",
    "- For supervised learning tasks, identify the target attribute(s).\n",
    "- Visualize the data. -> Scatterplot, HeatMaps etc\n",
    "- Study the correlations between attributes.\n",
    "- Study how you would solve the problem manually.\n",
    "- Identify the promising transformations you may want to apply.\n",
    "- Identify extra data that would be useful.\n",
    "- Document what you have learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50667f8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>bruises</th>\n",
       "      <th>odor</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-size</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>...</th>\n",
       "      <th>stalk-surface-below-ring</th>\n",
       "      <th>stalk-color-above-ring</th>\n",
       "      <th>stalk-color-below-ring</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>ring-number</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>population</th>\n",
       "      <th>habitat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>...</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4208</td>\n",
       "      <td>3656</td>\n",
       "      <td>3244</td>\n",
       "      <td>2284</td>\n",
       "      <td>4748</td>\n",
       "      <td>3528</td>\n",
       "      <td>7914</td>\n",
       "      <td>6812</td>\n",
       "      <td>5612</td>\n",
       "      <td>1728</td>\n",
       "      <td>...</td>\n",
       "      <td>4936</td>\n",
       "      <td>4464</td>\n",
       "      <td>4384</td>\n",
       "      <td>8124</td>\n",
       "      <td>7924</td>\n",
       "      <td>7488</td>\n",
       "      <td>3968</td>\n",
       "      <td>2388</td>\n",
       "      <td>4040</td>\n",
       "      <td>3148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       class cap-shape cap-surface cap-color bruises  odor gill-attachment  \\\n",
       "count   8124      8124        8124      8124    8124  8124            8124   \n",
       "unique     2         6           4        10       2     9               2   \n",
       "top        e         x           y         n       f     n               f   \n",
       "freq    4208      3656        3244      2284    4748  3528            7914   \n",
       "\n",
       "       gill-spacing gill-size gill-color  ... stalk-surface-below-ring  \\\n",
       "count          8124      8124       8124  ...                     8124   \n",
       "unique            2         2         12  ...                        4   \n",
       "top               c         b          b  ...                        s   \n",
       "freq           6812      5612       1728  ...                     4936   \n",
       "\n",
       "       stalk-color-above-ring stalk-color-below-ring veil-type veil-color  \\\n",
       "count                    8124                   8124      8124       8124   \n",
       "unique                      9                      9         1          4   \n",
       "top                         w                      w         p          w   \n",
       "freq                     4464                   4384      8124       7924   \n",
       "\n",
       "       ring-number ring-type spore-print-color population habitat  \n",
       "count         8124      8124              8124       8124    8124  \n",
       "unique           3         5                 9          6       7  \n",
       "top              o         p                 w          v       d  \n",
       "freq          7488      3968              2388       4040    3148  \n",
       "\n",
       "[4 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b99b7af4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>bruises</th>\n",
       "      <th>odor</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-size</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>...</th>\n",
       "      <th>stalk-surface-below-ring</th>\n",
       "      <th>stalk-color-above-ring</th>\n",
       "      <th>stalk-color-below-ring</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>ring-number</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>population</th>\n",
       "      <th>habitat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>y</td>\n",
       "      <td>t</td>\n",
       "      <td>a</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e</td>\n",
       "      <td>b</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>l</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p</td>\n",
       "      <td>x</td>\n",
       "      <td>y</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>g</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>w</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  class cap-shape cap-surface cap-color bruises odor gill-attachment  \\\n",
       "0     p         x           s         n       t    p               f   \n",
       "1     e         x           s         y       t    a               f   \n",
       "2     e         b           s         w       t    l               f   \n",
       "3     p         x           y         w       t    p               f   \n",
       "4     e         x           s         g       f    n               f   \n",
       "\n",
       "  gill-spacing gill-size gill-color  ... stalk-surface-below-ring  \\\n",
       "0            c         n          k  ...                        s   \n",
       "1            c         b          k  ...                        s   \n",
       "2            c         b          n  ...                        s   \n",
       "3            c         n          n  ...                        s   \n",
       "4            w         b          k  ...                        s   \n",
       "\n",
       "  stalk-color-above-ring stalk-color-below-ring veil-type veil-color  \\\n",
       "0                      w                      w         p          w   \n",
       "1                      w                      w         p          w   \n",
       "2                      w                      w         p          w   \n",
       "3                      w                      w         p          w   \n",
       "4                      w                      w         p          w   \n",
       "\n",
       "  ring-number ring-type spore-print-color population habitat  \n",
       "0           o         p                 k          s       u  \n",
       "1           o         p                 n          n       g  \n",
       "2           o         p                 n          n       m  \n",
       "3           o         p                 k          s       u  \n",
       "4           o         e                 n          a       g  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d93cafe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8124 entries, 0 to 8123\n",
      "Data columns (total 23 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   class                     8124 non-null   object\n",
      " 1   cap-shape                 8124 non-null   object\n",
      " 2   cap-surface               8124 non-null   object\n",
      " 3   cap-color                 8124 non-null   object\n",
      " 4   bruises                   8124 non-null   object\n",
      " 5   odor                      8124 non-null   object\n",
      " 6   gill-attachment           8124 non-null   object\n",
      " 7   gill-spacing              8124 non-null   object\n",
      " 8   gill-size                 8124 non-null   object\n",
      " 9   gill-color                8124 non-null   object\n",
      " 10  stalk-shape               8124 non-null   object\n",
      " 11  stalk-root                8124 non-null   object\n",
      " 12  stalk-surface-above-ring  8124 non-null   object\n",
      " 13  stalk-surface-below-ring  8124 non-null   object\n",
      " 14  stalk-color-above-ring    8124 non-null   object\n",
      " 15  stalk-color-below-ring    8124 non-null   object\n",
      " 16  veil-type                 8124 non-null   object\n",
      " 17  veil-color                8124 non-null   object\n",
      " 18  ring-number               8124 non-null   object\n",
      " 19  ring-type                 8124 non-null   object\n",
      " 20  spore-print-color         8124 non-null   object\n",
      " 21  population                8124 non-null   object\n",
      " 22  habitat                   8124 non-null   object\n",
      "dtypes: object(23)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6f0c9fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Bar plot for Column 0 \"edible\"\n",
    "df.iloc[:,0] = df.iloc[:,0].replace(\"e\",\"yes\") # replacing e with yes\n",
    "df.iloc[:,0] = df.iloc[:,0].replace(\"p\",\"no\")  # replacing p with no\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "df['class'].value_counts().plot(kind='bar', color=[\"green\", \"red\"], label='Edible')\n",
    "plt.title('Mushroom is edible')\n",
    "plt.xlabel('Edibile')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d6b732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Funktionen zur Assoziationsanalyse\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "def cramers_v(x, y):\n",
    "    ct = pd.crosstab(x, y)\n",
    "    n = ct.values.sum()\n",
    "    r, k = ct.shape\n",
    "    if r < 2 or k < 2:\n",
    "        return np.nan\n",
    "    chi2 = chi2_contingency(ct, correction=False)[0]\n",
    "    return np.sqrt(chi2 / (n * min(r-1, k-1)))\n",
    "\n",
    "def get_top_features(df: pd.DataFrame, target: str, top_n: int = 5) -> list:\n",
    "    scores = {\n",
    "        col: cramers_v(df[col], df[target])\n",
    "        for col in df.columns if col != target\n",
    "    }\n",
    "    # NaNs rausfiltern\n",
    "    scores = {k:v for k,v in scores.items() if not np.isnan(v)}\n",
    "    # sortiere absteigend\n",
    "    sorted_feats = sorted(scores.items(), key=lambda x: -x[1])\n",
    "    return [f for f,_ in sorted_feats[:top_n]]\n",
    "\n",
    "def nominal_assoc_matrix(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    cols = df.columns\n",
    "    M = pd.DataFrame(np.eye(len(cols)), index=cols, columns=cols)\n",
    "    for c1, c2 in combinations(cols, 2):\n",
    "        v = cramers_v(df[c1], df[c2])\n",
    "        M.loc[c1, c2] = M.loc[c2, c1] = v\n",
    "    return M\n",
    "\n",
    "# Assoziationsmatrix ausgeben (kann etwas dauern)\n",
    "V = nominal_assoc_matrix(df)\n",
    "display(V.style.background_gradient('Blues'))\n",
    "\n",
    "# Top-5 Features in Relation zur Zielklasse\n",
    "top5_strong_features = get_top_features(df, target='class', top_n=15)\n",
    "print(\"Top-5 Features nach Cramér’s V zum Ziel:\", top5_strong_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e8e9fe",
   "metadata": {},
   "source": [
    "# 4. Preparing the data\n",
    "\n",
    "Missing entries, represented by \"?\" were removed from the dataset.\n",
    "\n",
    "Afterwards the **categorical** feature values were mapped to numerical codes usind an Encoder. This transformation is necessary because numerical input rather than categorical strings are required.\n",
    "**One-Hot Encoding** is chosen over alternatives such as Label Encoding because it avoids introducing artificial ordinal relationships between categories and is suitable for our selected models (linear and tree-based).\n",
    "\n",
    "Since our dataset contains only categorical features (which are one-hot encoded), feature scaling is not necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bbfa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Fehlende Werte behandeln\n",
    "def handle_missing_values(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Entfernt Zeilen mit '?' in 'stalk-root'.\"\"\"\n",
    "    return df[df['stalk-root'] != '?'].copy()\n",
    "\n",
    "# 2) Label-Encoding für alle Spalten (einschließlich Ziel 'class')\n",
    "def encode_all_columns(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Label-encodiert jede Spalte in df.\n",
    "    Gibt zurück: (df_encoded, dict von LabelEncodern).\n",
    "    \"\"\"\n",
    "    df_encoded = df.copy()\n",
    "    label_encoders = {}\n",
    "    for col in df_encoded.columns:\n",
    "        le = LabelEncoder()\n",
    "        df_encoded[col] = le.fit_transform(df_encoded[col])\n",
    "        label_encoders[col] = le\n",
    "    return df_encoded, label_encoders\n",
    "\n",
    "# 3) Prepare-Funktion mit optionalem Ausschluss\n",
    "def prepare_data(\n",
    "    df: pd.DataFrame,\n",
    "    exclude_features: Optional[List[str]] = None,\n",
    "    test_size: float = 0.2,\n",
    "    random_state: int = 42\n",
    "):\n",
    "    \"\"\"\n",
    "    Führt full preprocessing durch:\n",
    "      - Missing-Value-Handling\n",
    "      - Optional Feature-Ausschluss\n",
    "      - Label-Encoding\n",
    "      - Train/Test-Split\n",
    "    \n",
    "    Returns: X_train, X_test, y_train, y_test, encoders\n",
    "    \"\"\"\n",
    "    # 3.1 Clean\n",
    "    df_clean = handle_missing_values(df)\n",
    "    \n",
    "    # 3.2 Optional starke Features entfernen\n",
    "    if exclude_features:\n",
    "        df_clean = df_clean.drop(columns=exclude_features, errors='ignore')\n",
    "        print(f\"Ausschluss: {exclude_features}\")\n",
    "    \n",
    "    # 3.3 Label-Encode alle Spalten\n",
    "    df_enc, encoders = encode_all_columns(df_clean)\n",
    "    \n",
    "    # 3.4 Merkmalsmatrix & Ziel\n",
    "    X = df_enc.drop(columns=['class'])\n",
    "    y = df_enc['class']\n",
    "    \n",
    "    # 3.5 Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y,\n",
    "        test_size=test_size,\n",
    "        stratify=y,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    print(f\"Train/Test Größe: {X_train.shape[0]}/{X_test.shape[0]}  — Features: {X.shape[1]}\")\n",
    "    return X_train, X_test, y_train, y_test, encoders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510069c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A) Datensatz mit ALLEN Features\n",
    "Xtr_all, Xte_all, ytr_all, yte_all, enc_all = prepare_data(\n",
    "    df, exclude_features=None\n",
    ")\n",
    "\n",
    "# B) Datensatz OHNE die starken Features\n",
    "Xtr_red, Xte_red, ytr_red, yte_red, enc_red = prepare_data(\n",
    "    df, exclude_features=top5_strong_features \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da940657",
   "metadata": {},
   "source": [
    "Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdefe6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder für alle Features\n",
    "categorical_all = Xtr_all.columns.tolist()\n",
    "ohe_all = ColumnTransformer([\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_all)\n",
    "], remainder='drop')\n",
    "\n",
    "# Encoder für die reduzierten Features\n",
    "categorical_red = Xtr_red.columns.tolist()\n",
    "ohe_red = ColumnTransformer([\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_red)\n",
    "], remainder='drop')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa241cd4",
   "metadata": {},
   "source": [
    "# 5. Selecting and training the model\n",
    "\n",
    "1. If the data is huge, sample smaller training sets so you can train many different models in a reasonable time. \n",
    "2. Try to automate the process as much as possible. \n",
    "3. Train many quick models from different categories (e.g., linear, naive Bayes, SVM, Rand. Forests, neural net, etc.) using standard parameters. \n",
    "4. Measure and compare performance: For each model, use N-fold cross-validation and compute mean and standard deviation of performance.\n",
    "5. Analyze the most significant attributes/features for each algorithm. \n",
    "6. Analyze the types of errors the models make: What data would a human have used to avoid these errors? \n",
    "7. Have a quick round of feature selection and feature engineering. \n",
    "8. Have one or two more quick iterations of the five previous steps. \n",
    "9. Short-list the top three to five most promising models, preferring models that make different types of errors.\n",
    "\n",
    "\n",
    "Models relevant for this project: `Logistic Regression`, `XGBoost` and `ThirdModelToBeChosen` (maybe a DecisionTree?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46a960a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_pipeline(pipe, Xtr, ytr, Xte, yte):\n",
    "    pipe.fit(Xtr, ytr)\n",
    "    # Merkmals-Transformation ohne Classifier\n",
    "    Xtr_f = pipe[:-1].transform(Xtr)\n",
    "    Xte_f = pipe[:-1].transform(Xte)\n",
    "    clf = pipe.named_steps['clf']\n",
    "    ytr_p = clf.predict(Xtr_f)\n",
    "    yte_p = clf.predict(Xte_f)\n",
    "    yte_prob = clf.predict_proba(Xte_f)[:,1]\n",
    "    return {\n",
    "        'Train Acc': accuracy_score(ytr, ytr_p),\n",
    "        'Test Acc' : accuracy_score(yte, yte_p),\n",
    "        'ROC-AUC'  : roc_auc_score(yte, yte_prob),\n",
    "        'pipe'     : pipe\n",
    "    }\n",
    "\n",
    "def plot_confusion(res_dict, Xte, yte, title):\n",
    "    from matplotlib import pyplot as plt\n",
    "    for name,res in res_dict.items():\n",
    "        pipe = res['pipe']\n",
    "        Xf = pipe[:-1].transform(Xte)\n",
    "        clf = pipe.named_steps['clf']\n",
    "        ypred = clf.predict(Xf)\n",
    "        disp = ConfusionMatrixDisplay.from_predictions(\n",
    "            yte, ypred,\n",
    "            display_labels=['edible','poisonous'], cmap=plt.cm.Blues\n",
    "        )\n",
    "        disp.ax_.set_title(f\"{title} — {name}\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505bdaea",
   "metadata": {},
   "source": [
    "### 5.1 XGBoost\n",
    "Training and testing  the xgboost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3ceb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgboost(X_tr, y_tr, X_te, y_te):\n",
    "    \"\"\"Train & eval XGBoost baseline.\"\"\"\n",
    "    pipe = Pipeline([\n",
    "        ('enc', ohe_preprocessor),\n",
    "        ('feat_sel', SelectFromModel(XGBClassifier(eval_metric='logloss', random_state=42), threshold='median')),\n",
    "        ('clf', XGBClassifier(eval_metric='logloss', random_state=42))\n",
    "    ])\n",
    "    return evaluate_pipeline(pipe, X_tr, y_tr, X_te, y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571dc3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb46053",
   "metadata": {},
   "source": [
    "### 5.2 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ad17ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_logistic(X_tr, y_tr, X_te, y_te):\n",
    "    \"\"\"Train & eval Logistic Regression baseline.\"\"\"\n",
    "    pipe = Pipeline([\n",
    "        ('enc', ohe_preprocessor),\n",
    "        ('scale', StandardScaler(with_mean=False)),\n",
    "        ('clf', LogisticRegression(max_iter=10000, random_state=42))\n",
    "    ])\n",
    "    return evaluate_pipeline(pipe, X_tr, y_tr, X_te, y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c00d09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f39c5f6e",
   "metadata": {},
   "source": [
    "### 5.3 Random Forest\n",
    "has been selected as the third model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41fc214",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_random_forest(X_tr, y_tr, X_te, y_te):\n",
    "    \"\"\"Train & eval Random Forest baseline.\"\"\"\n",
    "    pipe = Pipeline([\n",
    "        ('enc', ohe_preprocessor),\n",
    "        ('feat_sel', SelectFromModel(RandomForestClassifier(random_state=42), threshold='median')),\n",
    "        ('clf', RandomForestClassifier(random_state=42))\n",
    "    ])\n",
    "    return evaluate_pipeline(pipe, X_tr, y_tr, X_te, y_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f727fe8c",
   "metadata": {},
   "source": [
    "run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7acaf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion Factory, um per Encoder zu bauen:\n",
    "def make_pipelines(ohe):\n",
    "    return {\n",
    "        'LogReg': Pipeline([('enc',ohe),('scale',StandardScaler(with_mean=False)),('clf',LogisticRegression(max_iter=10000,random_state=42))]),\n",
    "        'RF'    : Pipeline([('enc',ohe),('fs',SelectFromModel(RandomForestClassifier(random_state=42),threshold='median')),('clf',RandomForestClassifier(random_state=42))]),\n",
    "        'XGB'   : Pipeline([('enc',ohe),('fs',SelectFromModel(XGBClassifier(eval_metric='logloss',random_state=42),threshold='median')),('clf',XGBClassifier(eval_metric='logloss',random_state=42))])\n",
    "    }\n",
    "\n",
    "# ALL\n",
    "pipes_all = make_pipelines(ohe_all)\n",
    "results_all = {name: evaluate_pipeline(pipe, Xtr_all, ytr_all, Xte_all, yte_all)\n",
    "               for name,pipe in pipes_all.items()}\n",
    "\n",
    "# REDUCED\n",
    "pipes_red = make_pipelines(ohe_red)\n",
    "results_red = {name: evaluate_pipeline(pipe, Xtr_red, ytr_red, Xte_red, yte_red)\n",
    "               for name,pipe in pipes_red.items()}\n",
    "\n",
    "# Ergebnisse ausgeben\n",
    "import pandas as pd\n",
    "print(\"=== ALL Features ===\")\n",
    "display(pd.DataFrame([{k:v for k,v in res.items() if k!='pipe'}]\n",
    "                     for res in results_all.values()).T.rename(columns=lambda x:list(results_all.keys())[x]))\n",
    "print(\"=== REDUCED Features ===\")\n",
    "display(pd.DataFrame([{k:v for k,v in res.items() if k!='pipe'}]\n",
    "                     for res in results_red.values()).T.rename(columns=lambda x:list(results_red.keys())[x]))\n",
    "\n",
    "# Konfusionsmatrizen plotten\n",
    "plot_confusion(results_all, Xte_all, yte_all, title=\"ALL Features\")\n",
    "plot_confusion(results_red, Xte_red, yte_red, title=\"REDUCED Features\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a1cb9e",
   "metadata": {},
   "source": [
    "### 5.4 Model Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41636d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "def summarize_results(results_dict):\n",
    "    \"\"\"Fasse die Kennzahlen in einem DataFrame zusammen.\"\"\"\n",
    "    rows = []\n",
    "    for name, res in results_dict.items():\n",
    "        rows.append({\n",
    "            'Model': name,\n",
    "            'Test Acc': res['Test Acc'],\n",
    "            'ROC-AUC' : res['ROC-AUC'],\n",
    "            'Overfit' : res['Train Acc'] - res['Test Acc']\n",
    "        })\n",
    "    return pd.DataFrame(rows).set_index('Model')\n",
    "\n",
    "# 1) Tabelle ausgeben\n",
    "print(\"=== ALL Features ===\")\n",
    "df_all = summarize_results(results_all)\n",
    "display(df_all)\n",
    "\n",
    "print(\"=== REDUCED Features ===\")\n",
    "df_red = summarize_results(results_red)\n",
    "display(df_red)\n",
    "\n",
    "\n",
    "# 2) ROC-Kurvenvergleich (manuell geplottet)\n",
    "def plot_roc_comparison_manual(results_dict, Xte, yte, title):\n",
    "    \"\"\"Zeichnet manuell ROC-Kurven für alle Modelle in results_dict.\"\"\"\n",
    "    plt.figure(figsize=(6,5))\n",
    "    for name, res in results_dict.items():\n",
    "        pipe = res['pipe']\n",
    "        # 1) Merkmals-Transformation ohne Klassifikator\n",
    "        Xf = pipe[:-1].transform(Xte)\n",
    "        # 2) Wahrscheinlichkeiten holen\n",
    "        prob = pipe.named_steps['clf'].predict_proba(Xf)[:, 1]\n",
    "        # 3) FPR/TPR berechnen\n",
    "        fpr, tpr, _ = roc_curve(yte, prob)\n",
    "        plt.plot(fpr, tpr, label=name, alpha=0.8)\n",
    "    # Diagonale als Zufallsbaseline\n",
    "    plt.plot([0,1], [0,1], 'k--', label='Chance')\n",
    "    plt.title(f\"ROC Curves — {title}\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_roc_comparison_manual(results_all, Xte_all, yte_all, \"ALL Features\")\n",
    "plot_roc_comparison_manual(results_red, Xte_red, yte_red, \"REDUCED Features\")\n",
    "\n",
    "\n",
    "# 3) Balkendiagramm der Kennzahlen\n",
    "def barplot_metric(df, metric, title):\n",
    "    plt.figure(figsize=(4,3))\n",
    "    df[metric].plot(kind='bar', ylim=(0,1), rot=0)\n",
    "    plt.title(f\"{title} — {metric}\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "barplot_metric(df_all, 'Test Acc', \"ALL Features\")\n",
    "barplot_metric(df_red, 'Test Acc', \"REDUCED Features\")\n",
    "barplot_metric(df_all, 'ROC-AUC',   \"ALL Features\")\n",
    "barplot_metric(df_red, 'ROC-AUC',   \"REDUCED Features\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea648b7f",
   "metadata": {},
   "source": [
    "### 5.5 (?) Error Analysis\n",
    "\n",
    "The confusion matrix reveals that the Random Forest model achieves nearly perfect classification on the test set. Only very few misclassifications occur. Given the structure of the dataset (purely categorical, with some highly predictive features like `odor` and `spore-print-color`), this result is expected.\n",
    "\n",
    "If a human were to classify mushrooms, they would likely rely on features like **odor, bruises, and gill characteristics**, which align with the model's most important features. Therefore, the model's decision process appears to be interpretable and biologically plausible.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad784c7",
   "metadata": {},
   "source": [
    "# 6. Fine-tuning the model\n",
    "\n",
    "General guidelines: \n",
    "1. Use as much data as possible for this step. \n",
    "2. As always automate what you can. \n",
    "3. Fine-tune the hyperparameters using cross-validation. \n",
    "4. Treat your data transformation choices as hyperparameters (e.g. replace missing values with zero or median? Or just drop the rows?). \n",
    "5. Unless there are very few hyperparamter values to explore, prefer random search over grid search. \n",
    "6. Try Ensemble methods. Combining your best models will often perform better than running them invdividually. \n",
    "7. Once you are confident about your final model, measure its performance on the test set to estimate the generalization error.\n",
    "8. Don't tweak your model after measuring the generalization error: you would just start overfitting the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcf3356",
   "metadata": {},
   "source": [
    "### 6.1 Fine-tuning XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f8ee38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameteroptimierung überlegen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ced128",
   "metadata": {},
   "source": [
    "### 6.2 Fine-tuning Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2936b6ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b1c8826",
   "metadata": {},
   "source": [
    "### 6.3 Fine-tuning Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9647f386",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cade92a5",
   "metadata": {},
   "source": [
    "# 7. Present your solution\n",
    "\n",
    "General guidelines: \n",
    "- Document what you have done. \n",
    "- Create a nice presentation: Make sure you highlight the big picture first. \n",
    "- Explain why your solution achieves the business objective. \n",
    "- Don't forget to present interesting points you noticed along the way. Describe what worked and what did not. List your assumptions and your system's limitations. \n",
    "- Ensure your key findings are communicated through beautiful visualizations or easy-toremember statements (e.g., \"the median income is the number-one predictor of housing prices\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b0891f",
   "metadata": {},
   "source": [
    "# 8. Launch, monitor and maintain\n",
    "\n",
    "General guidelines: \n",
    "- Get your solution ready for production (plug into production data inputs, write unit tests, etc.). \n",
    "- Write monitoring code to check your system's live performance at regular intervals and trigger alerts when it drops. Beware of slow degradation too: models tend to degrade as data evolves. Measuring performance may require a human pipeline (e.g., via a crowdsourcing service). Also monitor your inputs' quality (e.g., a malfunctioning sensor sending random values). This is particulary important for online learning systems. \n",
    "- Retrain your models on a regular basis on fresh data (automate as much as possible)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c8f6a8",
   "metadata": {},
   "source": [
    "# 9. Bonus: Analyzing the Influence of Top-Features and Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35221983",
   "metadata": {},
   "source": [
    "### 9.1 Influence of Top-Features on Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f679479",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0603a55b",
   "metadata": {},
   "source": [
    "### 9.2 Influence of Encoder Selection on Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e9e1f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
